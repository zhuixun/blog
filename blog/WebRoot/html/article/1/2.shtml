<!DOCTYPE html>

<html lang="cn">

<head>

<meta content="IE=10,IE=9,IE=8,ie=7" http-equiv="X-UA-Compatible">

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Mapreduce案例-数据去重|小倪的博客</title>

<meta content="大数据  hadoop hive hbase spark" name="keywords">

<meta content="bigdata  Hadoop HIve 大数据  Hbase spark" name="description">

<!--[if lt IE 9]><script src="../../../js/controlcenter/html5.js"></script><![endif]-->

<!-- Bootstrap -->

<link rel="stylesheet" href="../../../bootstrap/css/bootstrap.min.css">

<link rel="stylesheet" href="../../../css/blog.css">

<!-- 响应式css -->

<link rel="stylesheet" href="../../../bootstrap/css/bootstrap-responsive.css">

<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->

<script src="../../../js/jquery-1.10.2.min.js"></script>

<!-- Include all compiled plugins (below), or include individual files as needed -->

<script src="../../../bootstrap/js/bootstrap.min.js"></script>

<SCRIPT language=JavaScript src="../../../js/xmlhttp.js"></SCRIPT>

<!-- 代码高亮 -->

<script

	src="../../../js/controlcenter/ueditor/third-party/SyntaxHighlighter/shCore.js"

	type="text/javascript"></script>

<link

	href="../../../js/controlcenter/ueditor/third-party/SyntaxHighlighter/shCoreDefault.css"

	rel="stylesheet" type="text/css">

<script type="text/javascript" language="javascript">

	$(function() {

		SyntaxHighlighter.all();

	});

</script>
</head>

<body>

	<!-- nav -->

	<!--#include virtual="/WEB-INF/page/share/head.jsp" -->

	<!-- body -->

	<div class="container">

		<div class="row-fluid">

			<!-- content -->

			<div class="span12">

				<div class="well well-large blog-content">

					<div class="title-box">

						<ul class="date-b">

							<li class="date-m">12月</li>

							<li class="date-d">15日</li>

						</ul>

						<h1 class="article-title">Mapreduce案例-数据去重</h1>

					</div>

					<div class="article-content">

						<p>

							<span style="font-size: 16px;"><strong><span

									style="font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1：数据去重</span></strong></span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><span

								style="color: #FF0033;">“数据去重”</span>主要是利用并行化思想来对有意义的数据进行筛选。主要应用与网站日志独立ip统计，都会涉及一些数据去重。</span>

						</p>

						<p>

							<strong><span style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1.1案例描述</span></strong>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">对数据文件中数据进行去重，每行都是一个数据</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">案例<span

								style="color: #FF0033;">数据</span>如下：

							</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: #428BCA;">1）file1:</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-1

								a</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-2

								b</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-3

								c</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-4

								d</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-5

								a</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-6

								b</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-7

								c</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-3

								c</span>

						</p>

						<p>

							<span

								style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: #428BCA;">2)file2:</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-1

								b</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-2

								a</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-3

								b</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-4

								d</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-5

								a</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-6

								c</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-7

								d</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">2014-3-3

								c</span>

						</p>

						<p>

							<strong><span

								style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1.1案例去重设计思想</span></strong>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><span

								style="color: #FF0033;">数据去重</span>的目的是让出现多次的数据，最终只出现一次。mapreduce流程中，map的输出&lt;key,value&gt;经过shuffle过程聚集成&lt;key,value-list&gt;后交给reduce，也是按照key相同的值交给同一个reduce处理。我们把key作为reduce的输入数据，而对于value-list则没有要求，可以设置为<span

								style="color: #FF0033;">空值</span>。当reduce接收到一个&lt;key,value-list&gt;时就直接将key复制到输出key中。</span>

						</p>

						<p>

							<strong><span style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1.2程序代码</span></strong>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">具体程序代码如下：</span>

						</p>

							<pre class="brush:java;toolbar:false">package com.zwyq.mr;



import java.io.IOException;



import org.apache.hadoop.conf.Configuration;

import org.apache.hadoop.io.NullWritable;

import org.apache.hadoop.io.Text;

import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;

import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

import org.apache.hadoop.mapreduce.Job;

import org.apache.hadoop.mapreduce.Mapper;

import org.apache.hadoop.mapreduce.Reducer;

import org.apache.hadoop.util.GenericOptionsParser;

import org.apache.hadoop.fs.Path;



/**

 * 数据去重

 * @author niweiwei

 *

 */

public class DataToHeavy {

	//map将输入的值复制到输出的key上，并直接输出

	public static class Map extends Mapper&lt;Object, Text, Text, Text&gt;{

		public static Text line=new Text();//每行数据

		@Override

		protected void map(Object key, Text value, Context context)

				throws IOException, InterruptedException {

			line=value;

			context.write(line, new Text(&quot;&quot;));

		}

	}



	//Reduce将输入中的key复制到输出数据的key上，并且直接输出

	public static class Reduce extends Reducer&lt;Text, Text, Text, Text&gt;{



		@Override

		protected void reduce(Text key, Iterable&lt;Text&gt; values,Context context)

				throws IOException, InterruptedException {

			context.write(key, new Text(&quot;&quot;));

		}

	}



	public static void main(String[] args) throws IOException, ClassNotFoundException, InterruptedException {

	Configuration conf=new Configuration();

	

//	String[] otherArgs = new GenericOptionsParser(conf, args).getRemainingArgs();

//    if (otherArgs.length != 2) {

//      System.err.println(&quot;Usage: DataToHeavy &lt;in&gt; &lt;out&gt;&quot;);

//      System.exit(2);

//    }

		

	@SuppressWarnings(&quot;deprecation&quot;)

	Job job=new Job(conf,&quot;DataToHeavy&quot;);

	job.setJarByClass(DataToHeavy.class);

	

	//设置Map、Combiner和Reduce处理类

	job.setMapperClass(Map.class);

	job.setCombinerClass(Reduce.class);

	job.setReducerClass(Reduce.class);

	

	//设置输出类型

	job.setMapOutputKeyClass(Text.class);

	job.setMapOutputValueClass(Text.class);

	job.setOutputKeyClass(Text.class);

	job.setOutputValueClass(NullWritable.class);

	

	//设置输入和输出目录

	FileInputFormat.addInputPath(job, new Path(args[0]));

	FileOutputFormat.setOutputPath(job, new Path(args[1]));

	

	System.exit(job.waitForCompletion(true) ? 0 : 1);

	}

}</pre>

						<p>

							<strong><span

								style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1.3处理结果</span></strong>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; color: rgb(66, 139, 202);">1）：测试数据准备</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">先在hdfs目录user/hadoop下创建heavy目录，在hdfs创建目录，可以使用hadoop

								shell、hadoop api 、或者eclipse hadoop插件创建文件目录。这里用hadoop

								shell。如图下图所示，表示创建成功，命令如下。</span>

						</p>

						<p>

							<pre class="brush:java;toolbar:false">[hadoop@masternode hadoop]$ bin/hadoop fs -mkdir -p  /user/hadoop/heavy</pre>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><img

								src="/js/controlcenter/ueditor/jsp/upload1/20131215/81661400081819891.png"

								title="mkdir.png" /></span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">注意：不需要创建输出目录。</span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">在本地建立2个文本文件file1.txt和file2.txt，并且上传hdfs，如下图所示，命令如下：</span>

						</p>

						<p>

							<pre class="brush:java;toolbar:false">[hadoop@masternode hadoop]$ bin/hadoop fs -put /opt/hadoop/file1.txt  /user/hadoop/heavy

[hadoop@masternode hadoop]$ bin/hadoop fs -put /opt/hadoop/file2.txt  /user/hadoop/heavy</pre>

								

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><img

								src="/js/controlcenter/ueditor/jsp/upload1/20131215/66611400081884628.png"

								title="put.png" /></span>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">从putty远处查看”masternode“也能查看我们上传的两个文件。命令如下，如下图所示。</span>

						</p>

						<p>

							<pre class="brush:java;toolbar:false">[hadoop@masternode hadoop]$ bin/hadoop fs -ls /user/hadoop/heavy</pre>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><img

								src="/js/controlcenter/ueditor/jsp/upload1/20131215/35011400081948340.png"

								title="ls.png" /></span>

						</p>

						<p>

							<strong><span style="color: rgb(66, 139, 202); font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; font-size: 14px;">1）：运行结果查看</span></strong>

						</p>

						<p>

							<strong><span style="color: rgb(66, 139, 202); font-family: &amp; #39; Microsoft YaHei UI&amp;#39; , &amp;#39; Microsoft YaHei&amp;#39; , SimSun , &amp;#39; Segoe UI&amp;#39; , Tahoma , Helvetica, sans-serif, &amp;#39; Microsoft YaHei&amp;#39; , Georgia , Helvetica, Arial, sans-serif, 宋体, PMingLiU, serif; font-size: 13.684210777282715px; line-height: 22.105262756347656px;"><span

									id="_baidu_bookmark_start_107"

									style="display: none; line-height: 0px;">‍</span></span></strong><span

								id="_baidu_bookmark_start_109"

								style="display: none; line-height: 0px;">‍</span><span

								style="font-size: 14px; font-family: 微软雅黑,&amp; #39;">这时我们右击Eclipse的&quot;DFS

								Locations&quot;中&quot;/user/hadoop&quot;文件夹进行刷新，这时会发现多出一个&quot;heavy_out&quot;文件夹，且里面有2个文件，然后打开双其&quot;part-r-00000&quot;文件，会在Eclipse中间把内容显示出来。如图所示。</span><span

								id="_baidu_bookmark_end_110"

								style="display: none; line-height: 0px;">‍</span><strong><span

								style="color: rgb(66, 139, 202); font-family: &amp; #39; Microsoft YaHei UI&amp;#39; , &amp;#39; Microsoft YaHei&amp;#39; , SimSun , &amp;#39; Segoe UI&amp;#39; , Tahoma , Helvetica, sans-serif, &amp;#39; Microsoft YaHei&amp;#39; , Georgia , Helvetica, Arial, sans-serif, 宋体, PMingLiU, serif; font-size: 13.684210777282715px; line-height: 22.105262756347656px;"><span

									id="_baidu_bookmark_end_108"

									style="display: none; line-height: 0px;">‍</span></span></strong>

						</p>

						<p>

							<span style="font-size: 14px; font-family: 微软雅黑,&amp; #39;"><img

								src="/js/controlcenter/ueditor/jsp/upload1/20131215/7141400082300649.png"

								title="part.png" /></span>

						</p>

						<p>

							<strong><span style="color: rgb(66, 139, 202); font-family: 微软雅黑,&amp; #39; Microsoft YaHei&amp;#39;; font-size: 14px;"><br /></span></strong>

						</p>

					</div>
					<!-- 多说评论框 start -->
					<div class="ds-thread" data-thread-key="2" data-title="Mapreduce案例-数据去重|小倪的博客" data-url="/html/article/1/2.shtml"></div>
					<!-- 多说评论框 end -->
				</div>

			</div>

			<!-- Sidebar content -->
		</div>
	</div>
	<!-- footer -->
	<!--#include virtual="/WEB-INF/page/share/footer.jsp" -->
	<!-- 回到顶部 -->
	<script src="../../../js/scrolltopcontrol.js" type="text/javascript"><div class="rollto"><button class="btn btn-inverse" title="回顶部" data-type="totop"><i class="icon-eject icon-white"></i></button></div><script type="text/javascript">	// <![CDATA[	.fn = function() {	var position = function(element) {	var top = element.position().top, pos = element.css("position");	$(window).scroll(function() {	var scrolls = $(this).scrollTop();	if (scrolls > top) {	if (window.XMLHttpRequest) {	element.css({	position: "fixed",	top: 47	});	} else {	element.css({	top: scrolls	});	}	}else {	element.css({	position: pos,	top: top	});	}	});	};	return $(this).each(function() {	position($(this));	});	};	//绑定	$("#blad").smartFloat();	// ]]></script>

	<div id="topcontrol"

		style="position: fixed; bottom: 150px; right: 0px; opacity: 1; cursor: pointer;"

		title="返回顶部">

		<div class="totop">Top</div>
	</div>
</body>
</html>