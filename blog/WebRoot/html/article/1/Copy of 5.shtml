<!DOCTYPE html>
<html lang="cn">
<head>
	<meta content="IE=10,IE=9,IE=8,ie=7" http-equiv="X-UA-Compatible">
	<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<title>Hive安装和使用实践|小倪的博客</title>
	<meta content="Hive安装和使用实践,Hive 配置" name="keywords">
	<meta content="Hive安装和使用实践,hive 关联查询,hive 分区" name="description">
	<!--[if lt IE 9]><script src="../../../js/controlcenter/html5.js"></script><![endif]-->
	<!-- Bootstrap -->
	<link rel="stylesheet"  href="../../../bootstrap/css/bootstrap.min.css">
	<link rel="stylesheet" href="../../../css/blog.css">
	<!-- 响应式css -->
	<link rel="stylesheet" href="../../../bootstrap/css/bootstrap-responsive.css">
	<!-- jQuery (necessary for Bootstrap's JavaScript plugins) -->
	<script src="../../../js/jquery-1.10.2.min.js"></script>
	<!-- Include all compiled plugins (below), or include individual files as needed -->
	<script src="../../../bootstrap/js/bootstrap.min.js"></script>
	<SCRIPT language=JavaScript src="../../../js/xmlhttp.js"></SCRIPT>
	<!-- 代码高亮 -->
	<script src="../../../js/controlcenter/ueditor/third-party/SyntaxHighlighter/shCore.js" type="text/javascript"></script>
	<link href="../../../js/controlcenter/ueditor/third-party/SyntaxHighlighter/shCoreDefault.css" rel="stylesheet" type="text/css">
	<script type="text/javascript" language="javascript">
	$(function() {
		SyntaxHighlighter.all();
	});
	</script>
	<script type="text/javascript">


		 <!--
		 	function getClassifyList(){
				var classifyList = document.getElementById('classifyList');		
				if(classifyList){
					classifyList.innerHTML= "数据正在加载...";
					send_request(function(value){classifyList.innerHTML=value},
							 "/article/switch.do?method=classifyList", true);
				}
			}
        	function getArticleList(){
				var newestArticle = document.getElementById('newestArticle');		
				if(newestArticle){
					newestArticle.innerHTML= "数据正在加载...";
					send_request(function(value){newestArticle.innerHTML=value},
							 "/article/switch.do?method=newestArticle", true);
				}
			}
			function pageInit(){
				getArticleList();
				getClassifyList();
			}
         //-->
	</script>
</head>
<body onLoad="javascript:pageInit()">
<!-- nav -->
<!--#include virtual="/WEB-INF/page/share/head.jsp" -->
<!-- body -->
<div class="container">
	<div class="row-fluid">
		<!-- content -->
		<div class="span9">
			<div class="well well-large blog-content">
				<div class="title-box">
				<ul class="date-b">
					<li class="date-m">
					07月
					</li>
					<li class="date-d">
					07日
					</li>
				</ul>
				<h1 class="article-title">
					Hive安装使用
				</h1>
				</div>
				<div class="article-content">
					<p>13年学习hive使用的版本是Hive-0.9.0,现在是hive-0.12.0。最近要导入数据到mysql,但是单表30G的数据没有导入进去，估计即使导入进去查询也慢死了。选择hive来解决。正好复习回顾下hive的知识。<br/></p><p><strong>1.解压与安装</strong></p><p>解压hive-0.12.0.tar.gz<span style="font-size: 10.5pt; line-height: 1.5;">到/opt/目录下：</span></p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;Downloads]#&nbsp;tar&nbsp;-zxvf&nbsp;hive-0.12.0.tar.gz&nbsp;-C&nbsp;/opt/</pre><p>创建一个易记的hive目录</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;opt]#&nbsp;ln&nbsp;-s&nbsp;hive-0.12.0/&nbsp;&nbsp;hive</pre><p><strong>2.配置hive-env.sh</strong></p><p>Hive提供了一个模板文件hive-env.sh.template,复制成为hive-env.sh</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;hive]#&nbsp;cp&nbsp;conf/hive-env.sh.template&nbsp;conf/hive-env.sh</pre><p>修改<span style="font-size: 10.5pt; line-height: 1.5;">hive-env.sh文件，</span></p><p>配置HADOOP_HOME，将其设为hadoop所在目录，配置HIVE_CONF_DIR为hive配置文件所在目录</p><pre class="brush:bash;toolbar:false">[hadoop@masternode&nbsp;hive]$&nbsp;vi&nbsp;conf/hive-env.sh

HADOOP_HOME=/opt/hadoop

export&nbsp;HIVE_CONF_DIR=/opt/hive/conf</pre><p>配置JAVA_HOME(安装hadoop的时候配置好了，就跳过jdk配置)、配置HIVE的主目录，并把HIVE的bin加入环境变量</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;hive]#&nbsp;vi&nbsp;/etc/profile

#JDK

export&nbsp;JAVA_HOME=/usr/local/java/jdk

export&nbsp;PATH=$JAVA_HOME/bin:$PATH

#Hive

export&nbsp;HIVE_HOME=/opt/hive

export&nbsp;PATH=$PATH:$HIVE_HOME/bin</pre><p>使修改生效：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;hive]#&nbsp;source&nbsp;/etc/profile</pre><p><strong>3.配置conf/hive-site.xml</strong></p><p>默认没有提供<span style="font-size: 10.5pt; line-height: 1.5;">hive-site.xml,仅提供了配置模板</span>hive-default.xml.template，我们需要新建hive-site.xml</p><pre class="brush:bash;toolbar:false">[hadoop@masternode&nbsp;conf]$&nbsp;touch&nbsp;hive-site.xml</pre><p>在hive-site.xml中修改或添加：</p><pre class="brush:bash;toolbar:false">&lt;configuration&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;javax.jdo.option.ConnectionURL&lt;/name&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;jdbc:mysql://localhost:3306/hive?createDatabaseIfNotExist=true&lt;/value&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;JDBC&nbsp;connect&nbsp;string&nbsp;FOR&nbsp;a&nbsp;JDBC&nbsp;metastore&lt;/description&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;javax.jdo.option.ConnectionDriverName&lt;/name&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;com.mysql.jdbc.Driver&lt;/value&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;Driver&nbsp;class&nbsp;name&nbsp;FOR&nbsp;a&nbsp;JDBC&nbsp;metastore&lt;/description&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;javax.jdo.option.ConnectionUserName&lt;/name&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;root&lt;/value&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;username&nbsp;TOUSE&nbsp;against&nbsp;metastore&nbsp;database&lt;/description&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;property&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;name&gt;javax.jdo.option.ConnectionPassword&lt;/name&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;value&gt;root&lt;/value&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;description&gt;password&nbsp;TOUSE&nbsp;against&nbsp;metastore&nbsp;database&lt;/description&gt;

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&lt;/property&gt;

&lt;/configuration&gt;</pre><p><strong>4.mysql数据库安装，使用mysql管理Meta数据</strong></p><p>安装mysql:</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;setup]#&nbsp;yum&nbsp;-y&nbsp;install&nbsp;mysql&nbsp;mysql-server</pre><p>配置mysql默认编码：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;~]#&nbsp;vi&nbsp;/etc/my.cnf

#在[mysqlld]配置组下添加

[mysqld]

character-set-server=utf8

#新添加组[mysql]，如果组[mysql]已经存在，在需在组下加入便可

[mysql]

default-character-set=utf8</pre><p>设置mysql服务开机自动启动：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;/]#&nbsp;chkconfig&nbsp;mysqld&nbsp;on</pre><p>启动mysql服务：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;~]#&nbsp;service&nbsp;mysqld&nbsp;start</pre><p>设置mysql密码：</p><pre class="brush:bash;toolbar:false">mysql&gt;&nbsp;set&nbsp;password&nbsp;for&nbsp;root@localhost=password(&#39;root&#39;);</pre><p>创建Hive库，并设置编码：</p><pre class="brush:bash;toolbar:false">mysql&gt;&nbsp;create&nbsp;database&nbsp;hive;

mysql&gt;&nbsp;alter&nbsp;database&nbsp;hive&nbsp;character&nbsp;set&nbsp;latin1;</pre><p>把mysql的JDBC驱动包放入Hive的lib下：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;hive]#&nbsp;cp&nbsp;/root/Downloads/mysql-connector-java-3.1.13-bin.jar&nbsp;/opt/hive/lib/</pre><p>把hive-0.12.0目录权限赋给用户hadoop：</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;opt]#&nbsp;chown&nbsp;-R&nbsp;hadoop:hadoop&nbsp;hive-0.12.0</pre><p><strong>5.Hive的基本使用</strong></p><p>1.进入hive命令行：</p><pre class="brush:bash;toolbar:false">[hadoop@masternode&nbsp;hive]$&nbsp;bin/hive

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.input.dir.recursive&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.input.fileinputformat.input.dir.recursive

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.max.split.size&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.input.fileinputformat.split.maxsize

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.min.split.size&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.input.fileinputformat.split.minsize

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.min.split.size.per.rack&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.input.fileinputformat.split.minsize.per.rack

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.min.split.size.per.node&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.input.fileinputformat.split.minsize.per.node

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.reduce.tasks&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.job.reduces

14/06/18&nbsp;13:39:45&nbsp;INFO&nbsp;Configuration.deprecation:&nbsp;mapred.reduce.tasks.speculative.execution&nbsp;is&nbsp;deprecated.&nbsp;Instead,&nbsp;use&nbsp;mapreduce.reduce.speculative

Logging&nbsp;initialized&nbsp;using&nbsp;configuration&nbsp;in&nbsp;jar:file:/opt/hive-0.12.0/lib/hive-common-0.12.0.jar!/hive-log4j.properties

SLF4J:&nbsp;Class&nbsp;path&nbsp;contains&nbsp;multiple&nbsp;SLF4J&nbsp;bindings.

SLF4J:&nbsp;Found&nbsp;binding&nbsp;in&nbsp;[jar:file:/opt/hadoop-2.2.0/share/hadoop/common/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]

SLF4J:&nbsp;Found&nbsp;binding&nbsp;in&nbsp;[jar:file:/opt/hive-0.12.0/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]

SLF4J:&nbsp;See&nbsp;http://www.slf4j.org/codes.html#multiple_bindings&nbsp;for&nbsp;an&nbsp;explanation.

SLF4J:&nbsp;Actual&nbsp;binding&nbsp;is&nbsp;of&nbsp;type&nbsp;[org.slf4j.impl.Log4jLoggerFactory]

hive&gt;</pre><p>2.新建表</p><p>#创建数据以tab分割</p><pre class="brush:bash;toolbar:false">[root@masternode&nbsp;hadoop]#&nbsp;vi&nbsp;data_demo/data_hive.txt</pre><p>#创建表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;create&nbsp;table&nbsp;data_hive(a&nbsp;int,b&nbsp;int,c&nbsp;int)&nbsp;Row&nbsp;Format&nbsp;Delimited&nbsp;Fields&nbsp;Terminated&nbsp;By&nbsp;&#39;\t&#39;;

OK

Time&nbsp;taken:&nbsp;29.12&nbsp;seconds</pre><p>#导入数据data_hive.txt到data_hive表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;load&nbsp;data&nbsp;local&nbsp;inpath&nbsp;&#39;/home/hadoop/data_demo/data_hive.txt&#39;&nbsp;overwrite&nbsp;into&nbsp;table&nbsp;data_hive;

Copying&nbsp;data&nbsp;from&nbsp;file:/home/hadoop/data_demo/data_hive.txt

Copying&nbsp;file:&nbsp;file:/home/hadoop/data_demo/data_hive.txt

Loading&nbsp;data&nbsp;to&nbsp;table&nbsp;default.data_hive

Table&nbsp;default.data_hive&nbsp;stats:&nbsp;[num_partitions:&nbsp;0,&nbsp;num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;24,&nbsp;raw_data_size:&nbsp;0]

OK

Time&nbsp;taken:&nbsp;4.279&nbsp;seconds</pre><p>查看表和数据</p><p>#查看表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;show&nbsp;tables;

OK

data_hive

Time&nbsp;taken:&nbsp;0.604&nbsp;seconds,&nbsp;Fetched:&nbsp;1&nbsp;row(s)</pre><p>#正则匹配表名</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;show&nbsp;tables&nbsp;&#39;*data*&#39;;

OK

data_hive

Time&nbsp;taken:&nbsp;0.086&nbsp;seconds,&nbsp;Fetched:&nbsp;1&nbsp;row(s)</pre><p>#查看数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;*&nbsp;from&nbsp;data_hive;

OK

8	7	9

78	1	90

43	44	890

Time&nbsp;taken:&nbsp;1.223&nbsp;seconds,&nbsp;Fetched:&nbsp;3&nbsp;row(s)</pre><p>#查看表结构</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;desc&nbsp;data_hive;

OK

a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

Time&nbsp;taken:&nbsp;0.5&nbsp;seconds,&nbsp;Fetched:&nbsp;3&nbsp;row(s)</pre><p>修改表</p><p>#添加一个字段</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;alter&nbsp;table&nbsp;data_hive&nbsp;add&nbsp;columns&nbsp;(new_col&nbsp;String);

OK

Time&nbsp;taken:&nbsp;0.818&nbsp;seconds

hive&gt;&nbsp;desc&nbsp;data_hive;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

OK

a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

new_col&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	string&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

Time&nbsp;taken:&nbsp;0.522&nbsp;seconds,&nbsp;Fetched:&nbsp;4&nbsp;row(s)</pre><p>#修改表的名称</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;alter&nbsp;table&nbsp;data_hive&nbsp;rename&nbsp;to&nbsp;data_weibo;&nbsp;

OK

Time&nbsp;taken:&nbsp;1.492&nbsp;seconds

hive&gt;&nbsp;show&nbsp;tables;

OK

data_weibo

Time&nbsp;taken:&nbsp;0.201&nbsp;seconds,&nbsp;Fetched:&nbsp;1&nbsp;row(s)</pre><p>删除表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;drop&nbsp;table&nbsp;data_weibo;

OK

Time&nbsp;taken:&nbsp;2.524&nbsp;seconds

hive&gt;&nbsp;show&nbsp;tables;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

OK

Time&nbsp;taken:&nbsp;0.04&nbsp;seconds</pre><p>3.数据导入</p><p>还是以data_hive为例子。</p><p>#创建表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;create&nbsp;table&nbsp;data_hive(a&nbsp;int,b&nbsp;int,c&nbsp;int)&nbsp;Row&nbsp;Format&nbsp;Delimited&nbsp;Fields&nbsp;Terminated&nbsp;By&nbsp;&#39;\t&#39;;</pre><p>从操作系统本地文件加载数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;load&nbsp;data&nbsp;local&nbsp;inpath&nbsp;&#39;/home/hadoop/data_demo/data_hive.txt&#39;&nbsp;overwrite&nbsp;into&nbsp;table&nbsp;data_hive;

Copying&nbsp;data&nbsp;from&nbsp;file:/home/hadoop/data_demo/data_hive.txt

Copying&nbsp;file:&nbsp;file:/home/hadoop/data_demo/data_hive.txt

Loading&nbsp;data&nbsp;to&nbsp;table&nbsp;default.data_hive

Table&nbsp;default.data_hive&nbsp;stats:&nbsp;[num_partitions:&nbsp;0,&nbsp;num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;24,&nbsp;raw_data_size:&nbsp;0]

OK

Time&nbsp;taken:&nbsp;1.879&nbsp;seconds</pre><p>#在HDFS中查看导入的数据</p><pre class="brush:bash;toolbar:false">[hadoop@masternode&nbsp;hadoop]$&nbsp;bin/hadoop&nbsp;fs&nbsp;-cat&nbsp;/user/hive/warehouse/data_hive/data_hive.txt

8	7	9

78	1	90

43	44	890</pre><p>从HDFS加载数据</p><p>创建表data2_hive</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;create&nbsp;table&nbsp;data2_hive(a&nbsp;int,b&nbsp;int,c&nbsp;int)&nbsp;Row&nbsp;Format&nbsp;Delimited&nbsp;Fields&nbsp;Terminated&nbsp;By&nbsp;&#39;\t&#39;;

OK

Time&nbsp;taken:&nbsp;0.146&nbsp;seconds</pre><p>#从HDFS加载数据（去除local）</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;&nbsp;load&nbsp;data&nbsp;&nbsp;inpath&nbsp;&#39;/user/hive/warehouse/data_hive/data_hive.txt&#39;&nbsp;overwrite&nbsp;into&nbsp;table&nbsp;data2_hive;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

Loading&nbsp;data&nbsp;to&nbsp;table&nbsp;default.data2_hive

Table&nbsp;default.data2_hive&nbsp;stats:&nbsp;[num_partitions:&nbsp;0,&nbsp;num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;24,&nbsp;raw_data_size:&nbsp;0]

OK

Time&nbsp;taken:&nbsp;2.285&nbsp;seconds</pre><p>#查看数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;*&nbsp;from&nbsp;data2_hive;

OK

8	7	9

78	1	90

43	44	890

Time&nbsp;taken:&nbsp;0.453&nbsp;seconds,&nbsp;Fetched:&nbsp;3&nbsp;row(s)</pre><p>创建表并从其他表导入数据</p><pre class="brush:bash;toolbar:false">hive&gt;drop&nbsp;table&nbsp;data2_hive;

hive&gt;&nbsp;create&nbsp;table&nbsp;data2_hive&nbsp;as&nbsp;select&nbsp;*&nbsp;from&nbsp;data_hive;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

Total&nbsp;MapReduce&nbsp;jobs&nbsp;=&nbsp;3

Launching&nbsp;Job&nbsp;1&nbsp;out&nbsp;of&nbsp;3

Number&nbsp;of&nbsp;reduce&nbsp;tasks&nbsp;is&nbsp;set&nbsp;to&nbsp;0&nbsp;since&nbsp;there&#39;s&nbsp;no&nbsp;reduce&nbsp;operator

Starting&nbsp;Job&nbsp;=&nbsp;job_1403060200712_0002,&nbsp;Tracking&nbsp;URL&nbsp;=&nbsp;http://masternode:8088/proxy/application_1403060200712_0002/

Kill&nbsp;Command&nbsp;=&nbsp;/opt/hadoop-2.2.0/bin/hadoop&nbsp;job&nbsp;&nbsp;-kill&nbsp;job_1403060200712_0002

Hadoop&nbsp;job&nbsp;information&nbsp;for&nbsp;Stage-1:&nbsp;number&nbsp;of&nbsp;mappers:&nbsp;1;&nbsp;number&nbsp;of&nbsp;reducers:&nbsp;0

2014-06-18&nbsp;15:00:52,851&nbsp;Stage-1&nbsp;map&nbsp;=&nbsp;0%,&nbsp;&nbsp;reduce&nbsp;=&nbsp;0%

2014-06-18&nbsp;15:01:32,986&nbsp;Stage-1&nbsp;map&nbsp;=&nbsp;100%,&nbsp;&nbsp;reduce&nbsp;=&nbsp;0%,&nbsp;Cumulative&nbsp;CPU&nbsp;2.55&nbsp;sec

2014-06-18&nbsp;15:01:34,165&nbsp;Stage-1&nbsp;map&nbsp;=&nbsp;100%,&nbsp;&nbsp;reduce&nbsp;=&nbsp;0%,&nbsp;Cumulative&nbsp;CPU&nbsp;2.55&nbsp;sec

MapReduce&nbsp;Total&nbsp;cumulative&nbsp;CPU&nbsp;time:&nbsp;2&nbsp;seconds&nbsp;550&nbsp;msec

Ended&nbsp;Job&nbsp;=&nbsp;job_1403060200712_0002

Stage-4&nbsp;is&nbsp;selected&nbsp;by&nbsp;condition&nbsp;resolver.

Stage-3&nbsp;is&nbsp;filtered&nbsp;out&nbsp;by&nbsp;condition&nbsp;resolver.

Stage-5&nbsp;is&nbsp;filtered&nbsp;out&nbsp;by&nbsp;condition&nbsp;resolver.

Moving&nbsp;data&nbsp;to:&nbsp;hdfs://masternode:8020/tmp/hive-hadoop/hive_2014-06-18_15-00-04_571_4825376709172968018-1/-ext-10001

Moving&nbsp;data&nbsp;to:&nbsp;hdfs://masternode:8020/user/hive/warehouse/data2_hive

Table&nbsp;default.data2_hive&nbsp;stats:&nbsp;[num_partitions:&nbsp;0,&nbsp;num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;24,&nbsp;raw_data_size:&nbsp;0]

MapReduce&nbsp;Jobs&nbsp;Launched:&nbsp;

Job&nbsp;0:&nbsp;Map:&nbsp;1&nbsp;&nbsp;&nbsp;Cumulative&nbsp;CPU:&nbsp;2.55&nbsp;sec&nbsp;&nbsp;&nbsp;HDFS&nbsp;Read:&nbsp;244&nbsp;HDFS&nbsp;Write:&nbsp;24&nbsp;SUCCESS

Total&nbsp;MapReduce&nbsp;CPU&nbsp;Time&nbsp;Spent:&nbsp;2&nbsp;seconds&nbsp;550&nbsp;msec

OK

Time&nbsp;taken:&nbsp;91.375&nbsp;seconds</pre><p>复制表结构不导出数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;create&nbsp;table&nbsp;data3_hive&nbsp;like&nbsp;data_hive;

OK

Time&nbsp;taken:&nbsp;0.406&nbsp;seconds

hive&gt;&nbsp;desc&nbsp;data3_hive;

OK

a&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

c&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	int&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;	None&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

Time&nbsp;taken:&nbsp;0.934&nbsp;seconds,&nbsp;Fetched:&nbsp;3&nbsp;row(s)</pre><p>4.数据导出</p><p>通过HDFS拷贝到本地</p><pre class="brush:bash;toolbar:false">[hadoop@masternode&nbsp;hadoop]$&nbsp;bin/hadoop&nbsp;fs&nbsp;-copyToLocal&nbsp;/user/hive/warehouse/data_hive/data_hive.txt&nbsp;/opt/hadoop/localdata/

#查看数据

[hadoop@masternode&nbsp;hadoop]$&nbsp;ls&nbsp;localdata/

data_hive.txt</pre><p>5.Hive查询HiveQL</p><p>普通查询：排序，列别名，嵌套子查询</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;from(select&nbsp;b,c&nbsp;as&nbsp;c2&nbsp;from&nbsp;data_hive)&nbsp;t&nbsp;select&nbsp;t.b,t.c2&nbsp;where&nbsp;b&gt;2&nbsp;limit&nbsp;2;

Total&nbsp;MapReduce&nbsp;CPU&nbsp;Time&nbsp;Spent:&nbsp;3&nbsp;seconds&nbsp;640&nbsp;msec

OK

7	9

44	890

Time&nbsp;taken:&nbsp;131.112&nbsp;seconds,&nbsp;Fetched:&nbsp;2&nbsp;row(s)</pre><p>连接查询：JOIN</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;d1.a,d1.b,d2.a,d2.b&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;

&nbsp;&nbsp;&nbsp;&nbsp;&gt;&nbsp;from&nbsp;data_hive&nbsp;d1&nbsp;join&nbsp;data2_hive&nbsp;d2&nbsp;on&nbsp;d1.a=d2.a

&nbsp;&nbsp;&nbsp;&nbsp;&gt;&nbsp;where&nbsp;d1.c&gt;20;

78	1	78	1

43	44	43	44

Time&nbsp;taken:&nbsp;125.292&nbsp;seconds,&nbsp;Fetched:&nbsp;2&nbsp;row(s)</pre><p>聚合查询1：count, avg</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;count(*),avg(a)&nbsp;from&nbsp;data_hive;

3	43.0

Time&nbsp;taken:&nbsp;124.754&nbsp;seconds,&nbsp;Fetched:&nbsp;1&nbsp;row(s)</pre><p>聚合查询2：count, distinct</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;count(distinct&nbsp;b)&nbsp;from&nbsp;data_hive;

3

Time&nbsp;taken:&nbsp;122.915&nbsp;seconds,&nbsp;Fetched:&nbsp;1&nbsp;row(s)</pre><p>聚合查询3：GROUP BY</p><pre class="brush:bash;toolbar:false">#GROUP&nbsp;BY

hive&gt;&nbsp;select&nbsp;avg(a),b,sum(c)&nbsp;from&nbsp;data_hive&nbsp;group&nbsp;by&nbsp;b,c;

78.0	1	90

8.0	7	9

43.0	44	890

Time&nbsp;taken:&nbsp;164.604&nbsp;seconds,&nbsp;Fetched:&nbsp;3&nbsp;row(s)</pre><p>聚合查询3：<span style="font-size: 10.5pt; line-height: 1.5;">聚合查询3：GROUP BY</span></p><pre class="brush:bash;toolbar:false">#HAVING

hive&gt;&nbsp;select&nbsp;avg(a),b,sum(c)&nbsp;from&nbsp;data_hive&nbsp;group&nbsp;by&nbsp;b,c&nbsp;having&nbsp;sum(c)&gt;30;

78.0	1	90

43.0	44	890

Time&nbsp;taken:&nbsp;120.399&nbsp;seconds,&nbsp;Fetched:&nbsp;2&nbsp;row(s)</pre><p><strong>6.Hive分区表</strong></p><p>数据量很大的时候，考虑使用分区表。</p><p>查看数据（<span style="font-size: 10.5pt; line-height: 1.5;">数据截取部分显示</span><span style="font-size: 10.5pt; line-height: 1.5;">）</span></p><pre class="brush:bash;toolbar:false">#20140501.csv

56900437,kj,2014/05/01&nbsp;22:24:29,2014/05/01&nbsp;00:00:00.000

66596317,kj,2014/05/01&nbsp;22:24:29,2014/05/01&nbsp;00:00:00.000

65295414,kj,2014/05/01&nbsp;22:00:23,2014/05/01&nbsp;00:00:00.000

#20140502.csv

48056274,kj,2014/05/02&nbsp;22:28:50,2014/05/02&nbsp;00:00:00.000

48909721,kj,2014/05/02&nbsp;22:28:48,2014/05/02&nbsp;00:00:00.000

53962057,kj,2014/05/02&nbsp;22:28:45,2014/05/02&nbsp;00:00:00.000</pre><p>创建分区数据表</p><p>根据业务：按天进行分区设计</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;create&nbsp;table&nbsp;kj(userid&nbsp;int,viewlog_type&nbsp;string,startdt&nbsp;string,stopdt&nbsp;string)&nbsp;partitioned&nbsp;by(visit&nbsp;string)&nbsp;Row&nbsp;Format&nbsp;Delimited&nbsp;Fields&nbsp;Terminated&nbsp;By&nbsp;&#39;,&#39;;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;OK

Time&nbsp;taken:&nbsp;0.105&nbsp;seconds</pre><p>导入数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;load&nbsp;data&nbsp;inpath&nbsp;&#39;/user/hadoop/kj/20140501.csv&#39;&nbsp;overwrite&nbsp;into&nbsp;table&nbsp;kj&nbsp;partition&nbsp;(visit=20140501);&nbsp;&nbsp;&nbsp;

Loading&nbsp;data&nbsp;to&nbsp;table&nbsp;default.kj&nbsp;partition&nbsp;(visit=20140501)

Partition&nbsp;default.kj{visit=20140501}&nbsp;stats:&nbsp;[num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;2263233198,&nbsp;raw_data_size:&nbsp;0]

Table&nbsp;default.kj&nbsp;stats:&nbsp;[num_partitions:&nbsp;1,&nbsp;num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;2263233198,&nbsp;raw_data_size:&nbsp;0]

OK

Time&nbsp;taken:&nbsp;0.825&nbsp;seconds

hive&gt;&nbsp;load&nbsp;data&nbsp;inpath&nbsp;&#39;/user/hadoop/Kj/20140502.csv&#39;&nbsp;overwrite&nbsp;into&nbsp;table&nbsp;kj&nbsp;partition&nbsp;(visit=20140502);&nbsp;&nbsp;

Loading&nbsp;data&nbsp;to&nbsp;table&nbsp;default.kj&nbsp;partition&nbsp;(visit=20140502)

Partition&nbsp;default.kj{visit=20140502}&nbsp;stats:&nbsp;[num_files:&nbsp;1,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;2172499072,&nbsp;raw_data_size:&nbsp;0]

Table&nbsp;default.kj&nbsp;stats:&nbsp;[num_partitions:&nbsp;2,&nbsp;num_files:&nbsp;2,&nbsp;num_rows:&nbsp;0,&nbsp;total_size:&nbsp;4435732270,&nbsp;raw_data_size:&nbsp;0]

OK

Time&nbsp;taken:&nbsp;0.624&nbsp;seconds</pre><p>查看分区表</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;show&nbsp;partitions&nbsp;kj;

OK

visit=20140501

visit=20140502

Time&nbsp;taken:&nbsp;0.105&nbsp;seconds,&nbsp;Fetched:&nbsp;2&nbsp;row(s)</pre><p>查看数据</p><pre class="brush:bash;toolbar:false">hive&gt;&nbsp;select&nbsp;*&nbsp;from&nbsp;kj&nbsp;where&nbsp;visit=&#39;20140501&#39;;</pre><p>#由于数据量大，数据截取部分显示</p><pre class="brush:bash;toolbar:false">65040725&nbsp;&nbsp;&nbsp;&nbsp;kj&nbsp;&nbsp;&nbsp;&nbsp;2014/05/01&nbsp;17:06:48&nbsp;&nbsp;&nbsp;&nbsp;2014/05/01&nbsp;00:00:00.000

53934288&nbsp;&nbsp;&nbsp;&nbsp;kj&nbsp;&nbsp;&nbsp;&nbsp;2014/05/01&nbsp;17:06:43&nbsp;&nbsp;&nbsp;&nbsp;2014/05/01&nbsp;00:00:00.000

hive&gt;&nbsp;select&nbsp;*&nbsp;from&nbsp;kj&nbsp;where&nbsp;visit=&#39;20140502&#39;;

54588538	kj	2014/05/02&nbsp;19:56:01	2014/05/02&nbsp;00:00:00.000

65719279	kj	2014/05/02&nbsp;19:55:57	2014/05/02&nbsp;00:00:00.000

73143053	kj	2014/05/02&nbsp;19:55:56	2014/04/02&nbsp;00:00:00.000</pre><p>Hive基于的使用完成了，这些都是日常的操作。</p><p>转载请注明出处：</p><p><span style="color: rgb(0, 176, 240);"><a href="http://www.xnbigdata.com/html/article/1/5.shtml">http://www.xnbigdata.com/html/article/1/5.shtml</a></span></p><p><br/></p>
				</div>
				<!-- 多说评论框 start -->
				<div class="ds-thread" data-thread-key="5" data-title="Hive安装和使用实践|小倪的博客" data-url="/html/article/1/5.shtml"></div>
				<!-- 多说评论框 end -->
			</div>
		</div>
		<!-- Sidebar content -->
		<div class="span3">
			<!-- 日志分类 -->
			<div class="article-classify">
				<h3 class="classify-title">文章分类</h3>
				<ul class="classify-list pull-left" id="classifyList">
				</ul>
			</div>
			<!-- 最新文章 -->
			<div class="new-article">
				<h3 class="classify-title">最新文章</h3>
				<ul class="article-list pull-left" id="newestArticle">
				</ul>
			</div>


			<!-- 友情链接 -->
			<!--#include  virtual="/WEB-INF/page/share/links.jsp" -->
		</div>
	</div>
</div>


<!-- footer -->
<!--#include virtual="/WEB-INF/page/share/footer.jsp" -->
<!-- 回到顶部 -->
<script src="../../../js/scrolltopcontrol.js" type="text/javascript">
<div class="rollto">
<button class="btn btn-inverse" title="回顶部" data-type="totop">
<i class="icon-eject icon-white"></i>
</button>
</div>


<script type="text/javascript">
	// <![CDATA[
	.fn = function() {
	var position = function(element) {
	var top = element.position().top, pos = element.css("position");
	$(window).scroll(function() {
	var scrolls = $(this).scrollTop();
	if (scrolls > top) {
	if (window.XMLHttpRequest) {
	element.css({
	position: "fixed",
	top: 47
	});
	} else {


	element.css({


	top: scrolls


	});


	}


	}else {


	element.css({


	position: pos,


	top: top


	});


	}


	});
	};
	return $(this).each(function() {
	position($(this));
	});
	};
	//绑定
	$("#blad").smartFloat();
	// ]]>
</script>
<div id="topcontrol" style="position: fixed; bottom:150px; right:0px; opacity: 1; cursor: pointer;" title="返回顶部">
<div class="totop">Top</div>
</div>
</body>
</html>